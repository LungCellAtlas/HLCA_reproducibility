{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested clustering of cells in the HLCA, and cluster differential expression analysis (DEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we perform multi-level clustering of the cells in the HLCA (including final HLCA and benchmarking integrated HLCA subsets). We start with coarse-resolution clustering, and then re-cluster the resulting clusters by first re-calculating the nearest-neighbor graph and then clustering each cluster, with a finer resolution. For the final HLCA, we also calculate marker genes for every cluster. These will be used during manual annotation of the HLCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules, set paths, select atlas version to cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../../scripts/\")\n",
    "import nested_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pretty coding, not necessary to run code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_benchmarking_res = (\n",
    "    \"../../results/integration_benchmarking/benchmarking_results/integration/\"\n",
    ")\n",
    "dir_benchmarking_cluster_output = \"../../results/integration_benchmarking/clustering/\"\n",
    "\n",
    "path_HLCA = \"../../data/HLCA_core_h5ads/HLCA_v1_intermediates/HLCA_v1.h5ad\"  # this object is already doublet-filtered. Originally the unfiltered scANVI output was used, but it was not stored before filtering. To re-create it, use the combination of the preprocessed counts \"../../data/HLCA_core_h5ads/HLCA_v1_scANVI_input.h5ad\" and the scanvi output embedding \"../../results/scANVI_integration/scANVI_embedding.h5ad\"\n",
    "dir_HLCA_cluster_output = \"../../results/DEAs/leiden/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data to work with. We clustered the final HLCA using this notebook, but also other atlas integration generated during our integration benchmarking. We will use the clusters of the benchmarking output later to study rare cell identification with different integration methods. Choose one of the 4 lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"HLCA\"  # final, full HLCA\n",
    "# dataset_name = \"harmony\"  # benchmark\n",
    "# dataset_name = \"seuratrpca\"  # benchmark\n",
    "dataset_name = \"scanvi\"  # benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set number of cluster levels (we used 3 for benchmark methods and for final atlas, adding level 4 clustering for some clusters in the atlas that required finer resolution based on manual inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clust_levels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and perform clustering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the optimal integration for each of the benchmarking methods included, or the final atlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset name:\", dataset_name)\n",
    "if dataset_name == \"scanvi\":\n",
    "    # load dataset\n",
    "    adata = sc.read(\n",
    "        os.path.join(dir_benchmarking_res, \"unscaled/hvg/scanvi.h5ad\")\n",
    "    )\n",
    "    # specify which obsm to use for calculating neighbor graph\n",
    "    use_rep = \"X_emb\"\n",
    "    # specify whether or not to re-calculate the PCA for subsets of the object\n",
    "    redo_pca = False\n",
    "elif dataset_name == \"seuratrpca\":\n",
    "    adata = sc.read(\n",
    "        os.path.join(dir_benchmarking_res, \"unscaled/hvg/R/seuratrpca.h5ad\")\n",
    "    )\n",
    "    sc.tl.pca(adata)\n",
    "    use_rep = \"X_pca\"\n",
    "    redo_pca = True\n",
    "elif dataset_name == \"harmony\":\n",
    "    adata = sc.read(\n",
    "        os.path.join(dir_bencmarking_res, \"scaled/hvg/R/harmony.h5ad\")\n",
    "    )\n",
    "    adata.obsm[\"X_pca\"] = adata.obsm[\"X_emb\"]\n",
    "    use_rep = \"X_emb\"\n",
    "    redo_pca = False\n",
    "elif dataset_name == \"HLCA\":\n",
    "    adata = sc.read(path_HLCA)\n",
    "    use_rep = \"X_scanvi_emb\"\n",
    "    redo_pca = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize if a umap is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"X_umap\" in adata.obsm.keys():\n",
    "    if \"scanvi_labels\" in adata.obs.columns:\n",
    "        sc.pl.umap(adata, color=\"scanvi_labels\")\n",
    "    elif \"scgen_labels\" in adata.obs.columns:\n",
    "        sc.pl.umap(adata, color=\"scgen_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform multi-level clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clustering_level in range(1, number_of_clust_levels + 1):\n",
    "    print(\"clustering level:\", clustering_level, \"...\")\n",
    "    if clustering_level == 1:\n",
    "        # skip for re-run\n",
    "        cluster_name = \"leiden_1\"\n",
    "        # first clustering is not nested, so use normal function:\n",
    "        sc.pp.neighbors(adata, n_neighbors=30, use_rep=use_rep)\n",
    "        sc.tl.leiden(adata, resolution=0.01, key_added=cluster_name)\n",
    "    else:\n",
    "        previous_clustering = \"leiden_\" + str(clustering_level - 1)\n",
    "        cluster_name = \"leiden_\" + str(clustering_level)\n",
    "        #         perform nested clustering\n",
    "        #         set parameters:\n",
    "        res = 0.2\n",
    "        if clustering_level == 2:\n",
    "            k = 30\n",
    "            min_cluster_size = 50\n",
    "        elif clustering_level == 3:\n",
    "            k = 15\n",
    "            min_cluster_size = 30\n",
    "        elif clustering_level == 4:\n",
    "            k = 10\n",
    "            min_cluster_size = 10\n",
    "\n",
    "        adata = nested_clustering.add_nested_clustering_blind(\n",
    "            adata,\n",
    "            previous_clustering,\n",
    "            cluster_name,\n",
    "            use_rep=use_rep,\n",
    "            cluster_alg=\"leiden\",\n",
    "            cluster_k=k,\n",
    "            cluster_res=res,\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            redo_pca=redo_pca,  # SET THIS TO FALSE FOR SCANVI!!! OR OTHER EMBEDDING-OUTPUT METHODS!!!!!\n",
    "        )\n",
    "    # plot\n",
    "    if \"X_umap\" in adata.obsm.keys():\n",
    "        sc.pl.umap(adata, color=cluster_name)\n",
    "    # store clustering:\n",
    "    cluster_df = pd.DataFrame(adata.obs[cluster_name], index=adata.obs.index)\n",
    "    # write to csv for benchmarking data:\n",
    "    if dataset_name in [\"harmony\",\"scanvi\",\"seuratrpca\"]:\n",
    "        cluster_df.to_csv(\n",
    "            os.paht.join(dir_benchmarking_cluster_output, f\"{dataset_name}/{dataset_name}_{cluster_name}_cluster_assignment.csv\")\n",
    "        )\n",
    "    # If wanted/needed, for final HLCA:\n",
    "    if dataset_name == \"HLCA\":\n",
    "        # store cluster assignments:\n",
    "        cluster_df.to_csv(\n",
    "            os.paht.join(dir_HLCA_cluster_output, f\"LCA_{cluster_name}_cluster_assignment.csv\")\n",
    "        )\n",
    "        # calculate marker genes with respect to all other clusters, and with respect to sister clusters (i.e. other cluster from the same parent cluster):\n",
    "        for marker_ref in [\"sisters\", \"all\"]:\n",
    "            marker_gene_df = nested_clustering.get_cluster_markers(\n",
    "                adata=adata,\n",
    "                cluster_label=cluster_name,\n",
    "                marker_ref=marker_ref,\n",
    "                ngenes=100,\n",
    "            )\n",
    "            # and store:\n",
    "            marker_gene_df.to_csv(\n",
    "                os.path.join(dir_HLCA_cluster_output, f\"LCA_{cluster_name}_marker_genes_versus_{marker_ref}.csv\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### manual level 5 clustering where needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 1.2.1 in the HLCA (version 1), contains two different types of DCs, hence we re-cluster this level four cluster to get level 5 clusters for this specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"HLCA\":\n",
    "    cl_to_recluster = \"1.2.1.2\"\n",
    "    subadata = adata[adata.obs.leiden_4 == cl_to_recluster, :].copy()\n",
    "    sc.pp.neighbors(subadata, n_neighbors=10, use_rep=\"X_scanvi_emb\")\n",
    "    sc.tl.umap(subadata)\n",
    "    sc.tl.leiden(subadata, resolution=0.2, key_added=\"leiden_5\")\n",
    "    # plot and check which cluster is which:\n",
    "    sc.pl.umap(subadata, color=[\"CLEC9A\", \"CCR7\", \"leiden_4\", \"leiden_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"HLCA\":\n",
    "    # add clustering info to main object\n",
    "    adata.obs[\"leiden_5\"] = np.nan\n",
    "    adata.obs.loc[subadata.obs.index, \"leiden_5\"] = [\n",
    "        f\"{l4}.{l5}\" for l4, l5 in zip(subadata.obs.leiden_4, subadata.obs.leiden_5)\n",
    "    ]\n",
    "    # some plots for final checks:\n",
    "    sc.pl.umap(adata, color=\"leiden_5\")\n",
    "    sc.pl.umap(\n",
    "        adata,\n",
    "        color=[\"leiden_4\"],\n",
    "        groups=[\"1.2.1.0\", \"1.2.1.1\", \"1.2.1.2\", \"1.2.1.3\"],\n",
    "        ncols=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct color glitches for cellxgene proper functioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"HLCA\":\n",
    "    # make leiden 2 strings:\n",
    "    adata.obs['leiden_2'] = pd.Categorical(adata.obs.leiden_2.astype(str))\n",
    "    # and to add colors for leiden_3:\n",
    "    sc.pl.umap(adata, color='leiden_3', palette='nipy_spectral')\n",
    "    # store:\n",
    "    adata.write(path_HLCA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
