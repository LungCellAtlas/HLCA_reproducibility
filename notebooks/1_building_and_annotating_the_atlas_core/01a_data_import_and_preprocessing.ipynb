{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLCA PREPROCESSING  \n",
    "This notebook reads in the raw data included in the HLCA core, then adds sample and celltype annotations, harmonizes those, and performs minimal filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional extension, for automatic pretty-formatting of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out warnings if wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import sys\n",
    "\n",
    "# plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# self-written modules:\n",
    "sys.path.append(\"../../scripts/\")\n",
    "import utils\n",
    "import LCA_file_reading\n",
    "import preprocessing\n",
    "import reference_based_harmonizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data dir\n",
    "with open(\"../../../raw_data_path.txt\", \"r\") as file:\n",
    "    dir_data = file.readline().strip()\n",
    "# gene id to symbol mapping file:\n",
    "path_ens_mapper = (\n",
    "    \"../../supporting_files/gene_info/Homo_sapiens_GRCh38_84_gene_ids_to_gene_symbol.csv\"\n",
    ")\n",
    "# raw HLCA:\n",
    "path_raw_HLCA = \"../../data/HLCA_core_h5ads/HLCA_v1_intermediates/LCA_Bano_Barb_Jain_Kras_Lafy_Meye_Mish_MishBud_Nawi_Seib_Teic_RAW.h5ad\"\n",
    "# subject-filtered sample-annotated HLCA:\n",
    "path_subj_filt_samp_ann_HLCA = \"../../data/HLCA_core_h5ads/HLCA_v1_intermediates/LCA_Bano_Barb_Jain_Kras_Lafy_Meye_Mish_MishBud_Nawi_Seib_Teic_RAW_subjfilt_ann.h5ad\"\n",
    "# fully filtered sample-annotated and celltype annotated HLCA\n",
    "path_filt_ann_HLCA = \"../../data/HLCA_core_h5ads/HLCA_v1_intermediates/LCA_Bano_Barb_Jain_Kras_Lafy_Meye_Mish_MishBud_Nawi_Seib_Teic_RAW_filt_ann.h5ad\"\n",
    "# original to harmonized annotation mapping:\n",
    "path_celltype_mapping = \"../../supporting_files/metadata_harmonization/HLCA_cell_type_reference_mapping_20220712.csv\"\n",
    "# original to harmonized anatomical location mapping:\n",
    "path_anatomical_loc_mapping = \"../../supporting_files/metadata_harmonization/HLCA_anatomical_region_reference_mapping_20210521.csv\"\n",
    "# dir to sample level metadata:\n",
    "dir_sample_metadata = \"../../supporting_files/sample_level_metadata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### version info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: If you miss a compact list, please try `print_header`!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "anndata     0.7.4\n",
      "scanpy      1.7.2\n",
      "sinfo       0.3.1\n",
      "-----\n",
      "LCA_file_reading            NA\n",
      "PIL                         8.0.0\n",
      "anndata                     0.7.4\n",
      "appdirs                     1.4.4\n",
      "autoreload                  NA\n",
      "backcall                    0.1.0\n",
      "black                       20.8b1\n",
      "blib2to3                    NA\n",
      "click                       7.1.2\n",
      "cloudpickle                 1.2.2\n",
      "cycler                      0.10.0\n",
      "cython_runtime              NA\n",
      "dask                        2.9.1\n",
      "dateutil                    2.8.1\n",
      "decorator                   4.4.1\n",
      "dim_reduction               NA\n",
      "get_version                 2.1+py3.7.egg\n",
      "google                      NA\n",
      "h5py                        2.10.0\n",
      "igraph                      0.8.3\n",
      "ipykernel                   5.1.3\n",
      "ipython_genutils            0.2.0\n",
      "ipywidgets                  7.5.1\n",
      "jedi                        0.15.1\n",
      "joblib                      0.14.0\n",
      "kiwisolver                  1.1.0\n",
      "lab_black                   NA\n",
      "legacy_api_wrap             1.2+py3.7.egg\n",
      "leidenalg                   0.8.3\n",
      "llvmlite                    0.36.0\n",
      "louvain                     0.6.1\n",
      "matplotlib                  3.3.2\n",
      "more_itertools              NA\n",
      "mpl_toolkits                NA\n",
      "mypy_extensions             NA\n",
      "natsort                     6.2.0\n",
      "numba                       0.53.1\n",
      "numexpr                     2.7.0\n",
      "numpy                       1.17.4\n",
      "packaging                   20.4\n",
      "pandas                      1.0.5\n",
      "parso                       0.5.1\n",
      "pathspec                    0.8.0\n",
      "pexpect                     4.7.0\n",
      "pickleshare                 0.7.5\n",
      "pkg_resources               NA\n",
      "preprocessing               NA\n",
      "prompt_toolkit              2.0.10\n",
      "psutil                      5.6.7\n",
      "ptyprocess                  0.6.0\n",
      "pygments                    2.4.2\n",
      "pyparsing                   2.4.5\n",
      "pytz                        2019.3\n",
      "reference_based_harmonizing NA\n",
      "regex                       2.5.83\n",
      "scanpy                      1.7.2\n",
      "scib_excerpts               NA\n",
      "scipy                       1.5.4\n",
      "setuptools_scm              NA\n",
      "sinfo                       0.3.1\n",
      "six                         1.13.0\n",
      "sklearn                     0.24.1\n",
      "storemagic                  NA\n",
      "tables                      3.6.1\n",
      "texttable                   1.6.3\n",
      "toml                        0.10.1\n",
      "toolz                       0.10.0\n",
      "tornado                     6.0.3\n",
      "traitlets                   4.3.3\n",
      "typed_ast                   1.4.1\n",
      "typing_extensions           NA\n",
      "utils                       NA\n",
      "wcwidth                     NA\n",
      "zipp                        NA\n",
      "zmq                         18.1.0\n",
      "-----\n",
      "IPython             7.9.0\n",
      "jupyter_client      6.1.7\n",
      "jupyter_core        4.6.1\n",
      "jupyterlab          1.2.3\n",
      "notebook            6.0.2\n",
      "-----\n",
      "Python 3.7.5 (default, Oct 25 2019, 15:51:11) [GCC 7.3.0]\n",
      "Linux-3.10.0-1160.25.1.el7.x86_64-x86_64-with-centos-7.9.2009-Core\n",
      "48 logical CPU cores, x86_64\n",
      "-----\n",
      "Session information updated at 2022-02-24 11:57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.logging.print_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [\n",
    "    \"Banovich_Kropski_2020\",\n",
    "    \"Barbry_Leroy_2020\",\n",
    "    \"Jain_Misharin_2021\",\n",
    "    \"Krasnow_2020\",\n",
    "    \"Lafyatis_Rojas_2019\",\n",
    "    \"Meyer_2019\",\n",
    "    \"Misharin_2021\",\n",
    "    \"Misharin_Budinger_2018\",\n",
    "    \"Nawijn_2021\",\n",
    "    \"Seibold_2020\",\n",
    "    \"Teichmann_Meyer_2019\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_with_non_integer_values = list()\n",
    "adatas = dict()\n",
    "for study in studies:\n",
    "    print(\"\\nSTUDY:\", study)\n",
    "    project_dir = f\"{dir_data}{study}/\"\n",
    "    # note that the two **args are path to project dir and verbose\n",
    "    adata = getattr(LCA_file_reading, f\"read_file_{study}\")(project_dir, True)\n",
    "    # check if count matrices have only integer values:\n",
    "    print(\"checking if counts are integers...\")\n",
    "    test = np.sum(adata.X.toarray() % 1 == 0, axis=1)\n",
    "    nonint_adata = adata[test != adata.shape[1], :].copy()\n",
    "    nonint_adata.shape\n",
    "    if nonint_adata.shape[0] != 0:\n",
    "        print(\"WARNING: THIS DATASET HAS NON-INTEGER VALUES!!!\")\n",
    "        studies_with_non_integer_values.append(study)\n",
    "    else:\n",
    "        print(\"counts are integers.\")\n",
    "        adatas[study] = adata\n",
    "del adata, test, nonint_adata, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(studies_with_non_integer_values) != 0:\n",
    "    print(\"WARNING: THERE WERE DATASETS WITH NON-INTEGER VALUES!\")\n",
    "    print(studies_with_non_integer_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pool between datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData.concatenate(\n",
    "    *adatas.values(),\n",
    "    join=\"outer\",\n",
    "    batch_key=None,\n",
    "    batch_categories=list(adatas.keys()),\n",
    "    index_unique=None\n",
    ")\n",
    "print(adata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove gene symbol columns in adata.var (we will translate ids to symbols using ensembl 84 gtf file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.drop(columns=adata.var.columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_to_symbol_mapper = pd.read_csv(path_ens_mapper, index_col=0)\n",
    "# turn into dict:\n",
    "gene_id_to_symbol_mapper = dict(\n",
    "    zip(gene_id_to_symbol_mapper.index, gene_id_to_symbol_mapper.gene_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var[\"gene_symbols\"] = adata.var.index.map(gene_id_to_symbol_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set NANs in adata.X to zero, and shuffle rows (for unbiased plotting etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = np.nan_to_num(adata.X)\n",
    "index_list = np.arange(adata.shape[0])\n",
    "np.random.shuffle(index_list)\n",
    "adata = adata[index_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"nan\" in adata.obs.original_celltype_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.original_celltype_ann.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store/load result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.write(path_raw_HLCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(path_raw_HLCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cell reference annotation and filter cells:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original cell type labeling (as provided by dataset providers) will now be translated to the current version of the cell type ontology, consisting of 5 levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the .csv that contains the translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonizing_df = reference_based_harmonizing.load_harmonizing_table(\n",
    "    path_celltype_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe that contains each cell type name from the consensus ontology as indices, with their matching annotations at the other levels. This will simplify mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_df = reference_based_harmonizing.create_consensus_table(harmonizing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dataframe that for each original celltype annotation (from all datasets pooled) provides the translation to the consensus ontology at all levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_translation_df = (\n",
    "    reference_based_harmonizing.create_orig_ann_to_consensus_translation_df(\n",
    "        adata, consensus_df, harmonizing_df, verbose=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now translate the original annotations to the consensus in your AnnData:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = reference_based_harmonizing.consensus_annotate_anndata(\n",
    "    adata, celltype_translation_df, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now remove unicorns and artifacts (cells annotated as low quality, doublets etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unicorns and artifact cells to remove: 2338\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of unicorns and artifact cells to remove:\",\n",
    "    sum(adata.obs.original_ann_level_1 == \"Unicorns and artifacts\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592257, 33694)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs.original_ann_level_1 != \"Unicorns and artifacts\", :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589919, 33694)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add \"clean\" annotations (with \"None\" for cells that do not have annotation at that level):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = reference_based_harmonizing.add_clean_annotation(adata,input_ann_type=\"original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add sample/donor annotations from LCA metadata tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the naming of the _samples_ is harmonized rather than the donor naming, so use sample names to copy metadata to AnnData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCA_metadata_Misharin.csv\n",
      "LCA_metadata_Seibold.csv\n",
      "LCA_metadata_Krasnow.csv\n",
      "LCA_metadata_Banovich_Kropski.csv\n",
      "LCA_metadata_Nawijn.csv\n",
      "LCA_metadata_Meyer.csv\n",
      "LCA_metadata_Barbry.csv\n",
      "LCA_metadata_Lafyatis.csv\n",
      "number of rows without rowname/sample name (will be removed): 14\n",
      "Sample IDs unique? False\n",
      "Number of samples without donor ID: 0\n"
     ]
    }
   ],
   "source": [
    "metadata = preprocessing.get_sample_annotation_table_LCA(dir_sample_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove subjects with lung condition that we think will affect lung significantly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, check if there are any rows with \"known lung disease\" set to yes, but without specified condition. If there are, change the code in the cell below the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in metadata.loc[metadata.known_lung_disease == \"yes\", :].index:\n",
    "    matching_condition = metadata.loc[row, \"condition\"]\n",
    "    if pd.isnull(matching_condition) or matching_condition == \"nan\":\n",
    "        print(row, metadata.loc[row, \"condition\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now check set of lung conditions, and make selection of which ones to remove:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_conditions = [x for x in (set(metadata.condition)) if not pd.isnull(x)]\n",
    "lung_conditions_to_remove_from_data = [\n",
    "    lc\n",
    "    for lc in lung_conditions\n",
    "    if lc\n",
    "    # this is a list of the non-healthy subjects that we want to keep in,\n",
    "    # as the tissue that was sampled should not have been (dramatically)\n",
    "    # affected by the lung disease:\n",
    "    not in [\n",
    "        \"carcinoid (non-tumor tissue)\",\n",
    "        \"non-small cell lung cancer (non-tumor tissue)\",\n",
    "        \"had TB as a child (fully treated over 30+ years)\",\n",
    "        \"healthy\",\n",
    "        \"unknown\",\n",
    "        \"worsening respiratory function prior to arrest\",\n",
    "        \"acute pneumonia, sample from unaffected tissue\",\n",
    "        \"acute pneumonia, left lung, lower lobe, sample from unaffected tissue\"\n",
    "    ]\n",
    "]\n",
    "print(\"lung conditions to REMOVE from data:\")\n",
    "for i in lung_conditions_to_remove_from_data:\n",
    "    print(i)\n",
    "print(\"\\nlung conditions to KEEP in data:\")\n",
    "for i in lung_conditions:\n",
    "    if i not in lung_conditions_to_remove_from_data:\n",
    "        print(i)\n",
    "subjects_to_remove = sorted(\n",
    "    set(\n",
    "        metadata.loc[\n",
    "            metadata.condition.isin(lung_conditions_to_remove_from_data), \"subject_ID\"\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(\"\\nnumber of subjects to remove:\", len(subjects_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_in_adata = sorted(set(adata.obs[\"sample\"]))\n",
    "samples_in_metadata = metadata.index\n",
    "print(\"n samples in adata:\", len(samples_in_adata))\n",
    "if len(samples_in_metadata) != len(set(samples_in_metadata)):\n",
    "    print(\"WARNING: DUPLICATE SAMPLE NAMES IN METADATA TABLE! THIS SHOULD BE FIXED.\")\n",
    "for sample in samples_in_adata:\n",
    "    if sample not in samples_in_metadata:\n",
    "        print(sample, \"is in AnnData object but not in metadata. Check this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.index.value_counts().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns_to_drop = [\n",
    "    \"IF_AVAILABLE/_APPLICABLE_-->\",\n",
    "    \"Institute\",\n",
    "    \"Study_PI\",\n",
    "    \"library_ID\",\n",
    "    \"publication_ID\",\n",
    "    \"repository_ID\",\n",
    "    \"library-construction_batch\",\n",
    "    \"year_of_sample_collection\",\n",
    "    \"relative_sample_collection_timepoint\",\n",
    "    \"treatment_status\",\n",
    "    \"number_of_cells_loaded\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop(columns=metadata_columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in metadata.columns:\n",
    "    sample_to_cat_dict = dict(zip(metadata.index, metadata[cat]))\n",
    "    adata.obs[cat] = adata.obs[\"sample\"].map(sample_to_cat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can remove cells by subject ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_by_subject = ~adata.obs.subject_ID.isin(subjects_to_remove)\n",
    "print(\"removing\", sum(~filter_by_subject), \"cells from adata based on lung condition.\")\n",
    "adata = adata[filter_by_subject, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check within-dataset diversity of technical covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.groupby(\"study\").agg(\n",
    "    {\n",
    "        \"cell_ranger_version\": \"nunique\",\n",
    "        \"disease_status\": \"nunique\",\n",
    "        \"fresh_or_frozen\": \"nunique\",\n",
    "        \"known_lung_disease\": \"nunique\",\n",
    "        \"sample_type\": \"nunique\",\n",
    "        \"sequencing_platform\": \"nunique\",\n",
    "        \"single_cell_platform\": \"nunique\",\n",
    "        \"subject_type\": \"nunique\",\n",
    "        \"tissue_dissociation_protocol\": \"nunique\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write/read file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.write(path_subj_filt_samp_ann_HLCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(path_subj_filt_samp_ann_HLCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting of datasets into separate batches, where necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three datasets should be split into seperate batches (note that this is based on the [study_splitting_by_batch_effect_assessment.ipynb](./study_splitting_by_dataset_assessment.ipynb) notebook, in which we check which studies should be split up into multiple datasets based on experimental conditions, such as 10X chemistry).  \n",
    "    - lafyatis/rojas: different 10x versions  \n",
    "    - seibold: includes both 10x_3'_v2 and 10x_3'_v3  \n",
    "    - jain_misharin: 10x_5'_v1 and 10x_5'_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate sample to study dict, that will be updated with split datasets below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_study_df = adata.obs.groupby(\"sample\").agg(\n",
    "    {\n",
    "        \"sample\": \"first\",\n",
    "        \"study\": \"first\",\n",
    "        \"single_cell_platform\": \"first\",\n",
    "    }\n",
    ")\n",
    "sample_to_dataset_dict = dict(\n",
    "    zip(sample_to_study_df[\"sample\"], sample_to_study_df.study)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lafyatis/rojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_lafyatis_to_v1_dataset = {\n",
    "    sample: f\"{study}_10Xv1\"\n",
    "    for sample, study in sample_to_dataset_dict.items()\n",
    "    if study == \"Lafyatis_Rojas_2019\"\n",
    "    and sample_to_study_df.loc[sample, \"single_cell_platform\"] == \"10x_3'_v1\"\n",
    "}\n",
    "samples_lafyatis_to_v2_dataset = {\n",
    "    sample: f\"{study}_10Xv2\"\n",
    "    for sample, study in sample_to_dataset_dict.items()\n",
    "    if study == \"Lafyatis_Rojas_2019\"\n",
    "    and sample_to_study_df.loc[sample, \"single_cell_platform\"] == \"10x_3'_v2\"\n",
    "}\n",
    "sample_to_dataset_dict.update(samples_lafyatis_to_v1_dataset)\n",
    "sample_to_dataset_dict.update(samples_lafyatis_to_v2_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jain/misharin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_jain_to_v1_dataset = {\n",
    "    sample: f\"{study}_10Xv1\"\n",
    "    for sample, study in sample_to_dataset_dict.items()\n",
    "    if study == \"Jain_Misharin_2021\"\n",
    "    and sample_to_study_df.loc[sample, \"single_cell_platform\"] == \"10x_5'_v1\"\n",
    "}\n",
    "samples_jain_to_v2_dataset = {\n",
    "    sample: f\"{study}_10Xv2\"\n",
    "    for sample, study in sample_to_dataset_dict.items()\n",
    "    if study == \"Jain_Misharin_2021\"\n",
    "    and sample_to_study_df.loc[sample, \"single_cell_platform\"] == \"10x_5'_v2\"\n",
    "}\n",
    "sample_to_dataset_dict.update(samples_jain_to_v1_dataset)\n",
    "sample_to_dataset_dict.update(samples_jain_to_v2_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seibold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_seibold_to_v2_dataset = {\n",
    "    sample: f\"{study}_10Xv2\"\n",
    "    for sample, study in sample_to_dataset_dict.items()\n",
    "    if study == \"Seibold_2020\"\n",
    "    and sample_to_study_df.loc[sample, \"single_cell_platform\"] == \"10x_3'_v2\"\n",
    "}\n",
    "samples_seibold_to_v3_dataset = {\n",
    "    sample: f\"{study}_10Xv3\"\n",
    "    for sample, study in sample_to_dataset_dict.items()\n",
    "    if study == \"Seibold_2020\"\n",
    "    and sample_to_study_df.loc[sample, \"single_cell_platform\"] == \"10x_3'_v3\"\n",
    "}\n",
    "sample_to_dataset_dict.update(samples_seibold_to_v2_dataset)\n",
    "sample_to_dataset_dict.update(samples_seibold_to_v3_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now store resulting dataset assignments as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"dataset\"] = adata.obs[\"sample\"].map(sample_to_dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize anatomical region:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first add prefix to annotations from Barbry data, since their naming is inconsistent with other dataset's naming. Not adding prefix will result in mix-ups of translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix barbry detailed annotation with coarse, because otherwise detailed\n",
    "# mapping is many to one:\n",
    "# make into list, so that we can freely add new categories\n",
    "adata.obs[\"anatomical_region_detailed\"] = adata.obs[\n",
    "    \"anatomical_region_detailed\"\n",
    "].tolist()\n",
    "adata_barbry = adata[adata.obs[\"last_author_PI\"] == \"Barbry_Leroy\", :].copy()\n",
    "# check if prefixing was already done earlier:\n",
    "if (\n",
    "    sum(\n",
    "        [\n",
    "            fine.startswith(coarse)\n",
    "            for coarse, fine in zip(\n",
    "                adata_barbry.obs.anatomical_region_coarse,\n",
    "                adata_barbry.obs.anatomical_region_detailed,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    == adata_barbry.n_obs\n",
    "):\n",
    "    # if \"a\" == \"a\":\n",
    "    print(\"Fine anatomical regions barbry already prefixed.\")\n",
    "else:\n",
    "    barbry_region_detailed_prefixed = [\n",
    "        x + \"_\" + y\n",
    "        for x, y in zip(\n",
    "            adata_barbry.obs[\"anatomical_region_coarse\"],\n",
    "            adata_barbry.obs[\"anatomical_region_detailed\"],\n",
    "        )\n",
    "    ]\n",
    "    adata.obs.loc[\n",
    "        adata_barbry.obs.index, \"anatomical_region_detailed\"\n",
    "    ] = barbry_region_detailed_prefixed\n",
    "del adata_barbry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now harmonize anatomical region:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in harmonizing table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonizing_df = reference_based_harmonizing.load_harmonizing_table(path_anatomical_loc_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create translation table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_df = reference_based_harmonizing.create_consensus_table(\n",
    "    harmonizing_df, max_level=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "translate both levels (coarse and fine) to their harmonized counterpart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in [\"coarse\", \"fine\"]:\n",
    "    translation_df = (\n",
    "        reference_based_harmonizing.create_orig_ann_to_consensus_translation_df(\n",
    "            adata,\n",
    "            consensus_df,\n",
    "            harmonizing_df,\n",
    "            verbose=False,\n",
    "            ontology_type=\"anatomical_region_\" + res,\n",
    "        )\n",
    "    )\n",
    "    adata = reference_based_harmonizing.consensus_annotate_anndata(\n",
    "        adata,\n",
    "        translation_df,\n",
    "        verbose=False,\n",
    "        max_ann_level=3,\n",
    "        ontology_type=\"anatomical_region_\" + res,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge coarse and fine annotations, so that we keep the finest annotation available for every sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = reference_based_harmonizing.merge_coarse_and_fine_anatomical_ontology_anns(\n",
    "    adata, remove_harm_coarse_and_fine_original=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add ccf translation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = reference_based_harmonizing.add_anatomical_region_ccf_score(\n",
    "            adata, harmonizing_df\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age annotation (merging of age_in_years and age_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add age as merger of 'age, in years' and 'age, range'\n",
    "adata.obs[\"age\"] = [\n",
    "    preprocessing.age_converter(age, age_range)\n",
    "    for age, age_range in zip(adata.obs[\"age_in_years\"], adata.obs[\"age_range\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add digestion protocol information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_to_digest_prot = {\n",
    "    \"Barbry_Leroy_2020\": \"Cold protease 1h\",\n",
    "    \"Jain_Misharin_2021\": \"Cold protease 1h\",\n",
    "    \"Lafyatis_Rojas_2019\": \"Collagenase A + DNAse\",\n",
    "    \"Misharin_Budinger_2018\": \"Collagenase D + DNAse\",\n",
    "    \"Misharin_2021\": \"Collagenase D + DNAse\",\n",
    "    \"Nawijn_2021\": \"Collagenase D + DNAse\",\n",
    "    \"Teichmann_Meyer_2019\": \"Collagenase D + DNAse\",\n",
    "    \"Meyer_2019\": \"Collagenase D + DNAse\",\n",
    "    \"Banovich_Kropski_2020\": \"Dispase + collagenase\",\n",
    "    \"Krasnow_2020\": \"Collagenase + Elastase + DNAse\",\n",
    "    \"Seibold_2020\": \"Cold protease overnight\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"digestion\"] = adata.obs.study.map(study_to_digest_prot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if all variables have values for all cells:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we only expect that for some of them, but good to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in adata.obs.columns:\n",
    "    if adata.obs[cat].isnull().any():\n",
    "        print(cat, \"has null values\")\n",
    "    elif \"nan\" in adata.obs[cat]:\n",
    "        print(cat, \"has 'nan' values\")\n",
    "#     print(cat, adata.obs[cat].isnull().any(), \"nan\" in adata.obs[cat].values)\n",
    "#     if isinstance(adata.obs[cat].values, np.ndarray):\n",
    "#         print(cat, np.nan in adata.obs[cat].values, \"nan\" in adata.obs[cat].values)\n",
    "#     else:\n",
    "#         print(cat, adata.obs[cat].values.isna().any(), \"nan\" in adata.obs[cat].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if donor and sample names occur in only one dataset each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = adata.obs.groupby(\"sample\").agg({\"dataset\": \"nunique\"})\n",
    "# check if sample names only occur in one dataset:\n",
    "for sample in temp.index:\n",
    "    if temp.loc[sample, \"dataset\"] != 1:\n",
    "        print(str(sample) + \": this sample name occurs in multiple datasets\")\n",
    "temp = adata.obs.groupby(\"subject_ID\").agg({\"dataset\": \"nunique\"})\n",
    "for donor in temp.index:\n",
    "    if temp.loc[donor, \"dataset\"] != 1:\n",
    "        print(\n",
    "            str(donor)\n",
    "            + \": this subject_ID name occurs in \"\n",
    "            + str(temp.loc[donor, \"dataset\"])\n",
    "            + \" datasets!\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if all values have only zeros as decimals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store remainders of division by 1, count for each row number of entries for which remainder is not 0 (they should all be zero if data are integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.sum(adata.X.toarray() % 1 == 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select only those rows of adata that have non-integer values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonint_adata = adata[test != adata.shape[1], :].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check shape, it should have zero rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonint_adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if it doesn't have zero rows, then check which datasets have non-integer values (in that case we received non-raw counts from them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nonint_adata.obs.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter out cells with low numbers of genes expressed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out all cells with fewer than 200 genes expressed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of erythrocytes present before filtering: 332\n"
     ]
    }
   ],
   "source": [
    "# check how many erythrocytes are present before filtering:\n",
    "print(\n",
    "    \"Number of erythrocytes present before filtering:\",\n",
    "    np.sum(adata.obs.original_ann_level_3 == \"Erythrocytes\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells removed: 2335\n",
      "Number of cells pre-filtering: 589919\n",
      "Number of cells post filtering: 587584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(587584, 33694)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cells_pre = adata.shape[0]\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "n_cells_post = adata.shape[0]\n",
    "print(\"Number of cells removed: \" + str(n_cells_pre - n_cells_post))\n",
    "print(\"Number of cells pre-filtering: \" + str(n_cells_pre))\n",
    "print(\"Number of cells post filtering: \" + str(n_cells_post))\n",
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of erythrocytes present after filtering: 21\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of erythrocytes present after filtering:\",\n",
    "    np.sum(adata.obs.original_ann_level_3 == \"Erythrocytes\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out remaining erythrocytes; they generally have too un-diverse transcriptomes to be analyzed properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of erythrocytes removed: 21\n"
     ]
    }
   ],
   "source": [
    "n_cells_pre = adata.n_obs\n",
    "adata = adata[adata.obs.original_ann_level_3 != \"Erythrocytes\", :].copy()\n",
    "n_cells_post = adata.n_obs\n",
    "print(\"Number of erythrocytes removed:\", n_cells_pre - n_cells_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add QC annotations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate qc metrics, such as counts per cell, percentage of mitochondrial RNA etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate with QC stuff:\n",
    "adata = preprocessing.add_cell_annotations(adata, var_index=\"gene_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out genes expressed in low number of cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes removed: 5167\n",
      "Number of genes pre-filtering: 33694\n",
      "Number of genes post filtering: 28527\n"
     ]
    }
   ],
   "source": [
    "n_genes_pre = adata.shape[1]\n",
    "sc.pp.filter_genes(adata, min_cells=10)\n",
    "n_genes_post = adata.shape[1]\n",
    "print(\"Number of genes removed: \" + str(n_genes_pre - n_genes_post))\n",
    "print(\"Number of genes pre-filtering: \" + str(n_genes_pre))\n",
    "print(\"Number of genes post filtering: \" + str(n_genes_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### harmonize nan/None/\"nan\" etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all different types of None/NaN to np.nan\n",
    "none_entries = adata.obs.applymap(utils.check_if_nan)\n",
    "adata.obs = adata.obs.mask(none_entries.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'ann_level_1' as categorical\n",
      "... storing 'ann_level_2' as categorical\n",
      "... storing 'ann_level_3' as categorical\n",
      "... storing 'ann_level_4' as categorical\n",
      "... storing 'ann_level_5' as categorical\n"
     ]
    }
   ],
   "source": [
    "adata.write(path_filt_ann_HLCA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
